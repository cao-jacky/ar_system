{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:23.017762Z",
     "start_time": "2019-11-18T13:02:22.798015Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mmap\n",
    "\n",
    "import pickle\n",
    "import multiprocessing \n",
    "\n",
    "import csv\n",
    "\n",
    "import gmplot\n",
    "from os import path\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:23.059795Z",
     "start_time": "2019-11-18T13:02:23.056661Z"
    }
   },
   "outputs": [],
   "source": [
    "curr_day = \"071119\"\n",
    "\n",
    "# Searching through server logs - no particular need to do so\n",
    "server_log_folder = \"./server_logs/\" + curr_day\n",
    "server_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(server_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            server_folder_files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:23.357647Z",
     "start_time": "2019-11-18T13:02:23.288455Z"
    }
   },
   "outputs": [],
   "source": [
    "# parse through the test_receive.txt file from server\n",
    "\n",
    "rec_frames = []\n",
    "\n",
    "test_receive = \"server_logs/\" + curr_day + \"/test_receive.txt\"\n",
    "with open(test_receive) as search:\n",
    "    for line in search:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if \"receive frameID :\" in line:\n",
    "            frame_no = int(re.findall(r'receive frameID :(.+?), at time :', line)[0])\n",
    "            rec_frames.append(frame_no)\n",
    "            \n",
    "frames = np.zeros([len(rec_frames), 13])\n",
    "\"\"\" \n",
    "The columns represent:\n",
    "[0] : frame ID\n",
    "[1] : frame size received\n",
    "[2] : transmission delay\n",
    "[3] : size of the result sent\n",
    "[4] : time result was sent from server \n",
    "[5] : time taken to process the frame\n",
    "[6] : time the frame was sent from device\n",
    "[7] : time a result was received on the device\n",
    "[8] : whether connection was 5G or 4G when frame sent from device\n",
    "[9] : whether connection was 5G or 4G when result recieved on device\n",
    "[10] : whether a handover occured between frame sent and result received on device\n",
    "[11] : closest location: latitude\n",
    "[12] : closest location: longitude\n",
    "\"\"\"\n",
    "\n",
    "# reading the number of lines in the file\n",
    "with open(test_receive) as f:\n",
    "    num_lines_tr = sum(1 for _ in f)\n",
    "    \n",
    "contents_tr = open(test_receive, \"r\").readlines()\n",
    "no_frame_parsed = 0 \n",
    "for i in range(num_lines_tr):\n",
    "    curr_line = contents_tr[i]\n",
    "    \n",
    "    if \"receive frameID :\" in curr_line:\n",
    "        frame_no = int(re.findall(r'receive frameID :(.+?), at time :', curr_line)[0])\n",
    "        frames[no_frame_parsed][0] = frame_no\n",
    "        \n",
    "        frame_size_rec = float(re.findall(r', has size:(.+?), transmission delay:', curr_line)[0])\n",
    "        frames[no_frame_parsed][1] = frame_size_rec\n",
    "        \n",
    "        no_frame_parsed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:23.664797Z",
     "start_time": "2019-11-18T13:02:23.568439Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse through the test_send.txt file from server\n",
    "\n",
    "sent_frames = []\n",
    "\n",
    "test_send = \"server_logs/\" + curr_day + \"/test_send.txt\"\n",
    "with open(test_send) as search:\n",
    "    for line in search:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if \"send_result of frameID of:\" in line:\n",
    "            frame_no = int(re.findall(r'send_result of frameID of:(.+?)sent by observer at time:', line)[0])\n",
    "            sent_frames.append(frame_no)\n",
    "            \n",
    "# reading the number of lines in the file\n",
    "with open(test_send) as f:\n",
    "    num_lines_ts = sum(1 for _ in f)\n",
    "    \n",
    "contents_ts = open(test_send, \"r\").readlines()\n",
    "no_frame_parsed = 0 \n",
    "for i in range(num_lines_ts):\n",
    "    curr_line = contents_ts[i]\n",
    "    \n",
    "    if \"send_result of frameID of:\" in curr_line:\n",
    "        frame_no = int(re.findall(r'send_result of frameID of:(.+?)sent by observer at time:', curr_line)[0])\n",
    "        if frame_no == frames[no_frame_parsed][0]:\n",
    "            frame_size_sent = curr_line.split(\" \")[-1]\n",
    "            frames[no_frame_parsed][3] = frame_size_sent\n",
    "            \n",
    "            frame_time_sent = float(re.findall(r'sent by observer at time:(.+?)whose size is:', line)[0])\n",
    "            frames[no_frame_parsed][4] = frame_time_sent\n",
    "        \n",
    "        no_frame_parsed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:24.053563Z",
     "start_time": "2019-11-18T13:02:23.971330Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse through the test_process.txt file from server\n",
    "\n",
    "process_frames = []\n",
    "\n",
    "test_process = \"server_logs/\" + curr_day + \"/test_process.txt\"\n",
    "with open(test_process) as search:\n",
    "    for line in search:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if \"time_process_pic of frameid of:\" in line:\n",
    "            frame_no = int(re.findall(r'time_process_pic of frameid of:(.+?)takes: ', line)[0])\n",
    "            process_frames.append(frame_no)\n",
    "            \n",
    "# reading the number of lines in the file\n",
    "with open(test_process) as f:\n",
    "    num_lines_tp = sum(1 for _ in f)\n",
    "    \n",
    "contents_tp = open(test_process, \"r\").readlines()\n",
    "no_frame_parsed = 0 \n",
    "for i in range(num_lines_tp):\n",
    "    curr_line = contents_tp[i]\n",
    "    \n",
    "    if \"time_process_pic of frameid of:\" in curr_line:\n",
    "        frame_no = int(re.findall(r'time_process_pic of frameid of:(.+?)takes: ', curr_line)[0])\n",
    "        if frame_no == frames[no_frame_parsed][0]:\n",
    "            frame_process_time = re.findall(r'takes:(.+?)milliseconds', curr_line)[0]\n",
    "            frame_process_time = float(re.findall(r\"'(.+?)'\", frame_process_time)[0])\n",
    "            frames[no_frame_parsed][5] = frame_process_time\n",
    "        \n",
    "        no_frame_parsed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:24.243506Z",
     "start_time": "2019-11-18T13:02:24.233170Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Searching through device logs \n",
    "\n",
    "client_log_folder = \"./device_logs/arhud_logs/\"\n",
    "client_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(client_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            client_folder_files.append(os.path.join(r, file))\n",
    "            \n",
    "device_log_files = []\n",
    "for curr_file in client_folder_files:\n",
    "    cf_orig = curr_file\n",
    "    curr_file = curr_file.split(\"/\")[-1].split(\"_\")\n",
    "    cf_time = float(curr_file[1].split(\".txt\")[0]) / 1000\n",
    "    \n",
    "    file_info = [str(cf_time), cf_orig]\n",
    "    globals()[\"device_log_files\"].append(file_info)\n",
    "\n",
    "# sort by unix_timestamp and manually select files from 071119\n",
    "device_log_files = sorted(device_log_files, key=operator.itemgetter(0))[-6:]\n",
    "\n",
    "# print(device_log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:24.803912Z",
     "start_time": "2019-11-18T13:02:24.438303Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse through client logcat files\n",
    "\n",
    "client_sent_frames = []\n",
    "client_received_frames = []\n",
    "\n",
    "location_changes = []\n",
    "\n",
    "for i in range(len(device_log_files)):\n",
    "    curr_log_item = device_log_files[i]\n",
    "    curr_log_file = curr_log_item[1]\n",
    "    \n",
    "    # reading the number of lines in the file\n",
    "    with open(curr_log_file) as f:\n",
    "        num_lines_cf = sum(1 for _ in f)\n",
    "\n",
    "    contents_cl = open(curr_log_file, \"r\").readlines()\n",
    "    for i in range(num_lines_cf):\n",
    "        curr_line = contents_cl[i]\n",
    "\n",
    "        if \"sent at\" in curr_line:\n",
    "            frame_no = int(re.findall(r'Frame(.+?)sent at', curr_line)[0])\n",
    "            frame_time_sent = curr_line.split(\" \")[-1].replace('\\n', '')   \n",
    "        \n",
    "            frame_data = [frame_no, frame_time_sent, \"sent\"]            \n",
    "            client_sent_frames.append(frame_data)\n",
    "            \n",
    "        if \"received at\" in curr_line:\n",
    "            frame_no = int(re.findall(r'res for frame(.+?)received at', curr_line)[0])\n",
    "            res_time_rec = curr_line.split(\" \")[-1].replace('\\n', '')   \n",
    "        \n",
    "            frame_data = [frame_no, res_time_rec, \"received\"]     \n",
    "            client_received_frames.append(frame_data)\n",
    "            \n",
    "        if \"location is\" in curr_line:\n",
    "            split_curr_line = curr_line.split(\" \")\n",
    "            lat = split_curr_line[12]\n",
    "            long = split_curr_line[15]\n",
    "            loc_time = split_curr_line[9]\n",
    "            \n",
    "            location_changes.append([lat, long, loc_time, frame_no])\n",
    "            \n",
    "#print(client_sent_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:49.532616Z",
     "start_time": "2019-11-18T13:02:24.805049Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# matching up the client_sent_frames list and the server received frames array\n",
    "\n",
    "server_received = list(frames[:,0])\n",
    "csf = [item[0] for item in client_sent_frames]\n",
    "\n",
    "matched_frames = []\n",
    "for i in range(len(server_received)):\n",
    "    curr_sf_id = server_received[i]\n",
    "    match_s_c = np.where(csf == curr_sf_id)[0]\n",
    "    \n",
    "    if not match_s_c.size == 0:\n",
    "        first_c_id = int(match_s_c[0])\n",
    "\n",
    "        # add client data to matched_frames list\n",
    "        matched_frames.append(client_sent_frames[first_c_id])\n",
    "        #print(curr_sf_id, first_c_id, len(matched_frames))\n",
    "    \n",
    "with open(\"matched_client_sent_frames.txt\", \"wb\") as fp:\n",
    "    pickle.dump(matched_frames, fp)\n",
    "#print(matched_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:49.556681Z",
     "start_time": "2019-11-18T13:02:49.533928Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# load the matched_client_frames.txt file and then store the timestamp into frames\n",
    "\n",
    "with open(\"matched_client_sent_frames.txt\", \"rb\") as input_file:\n",
    "    mcsf = pickle.load(input_file)\n",
    "    \n",
    "for i in range(len(mcsf)):\n",
    "    curr_cf = mcsf[i]\n",
    "    ccf_id = curr_cf[0]\n",
    "    ccf_time = curr_cf[1]\n",
    "    \n",
    "    csf_id = frames[i][0]\n",
    "    \n",
    "    if ccf_id == csf_id:\n",
    "        frames[i][6] = ccf_time\n",
    "    else:\n",
    "        new_id = frames[i+1][0]\n",
    "        if ccf_id == new_id:\n",
    "            frames[i+1][6] = ccf_time\n",
    "        else:\n",
    "            new_id = frames[i+2][0]\n",
    "            if ccf_id == new_id:\n",
    "                frames[i+2][6] = ccf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:56.067732Z",
     "start_time": "2019-11-18T13:02:49.557925Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# matching up the server sent and client received\n",
    "\n",
    "server_received = list(frames[:,0])\n",
    "crf = [item[0] for item in client_received_frames]\n",
    "\n",
    "matched_frames = []\n",
    "for i in range(len(server_received)):\n",
    "    curr_sf_id = server_received[i]\n",
    "    match_s_c = np.where(crf == curr_sf_id)[0]\n",
    "    \n",
    "    if not match_s_c.size == 0:\n",
    "        first_c_id = int(match_s_c[0])\n",
    "\n",
    "        # add client data to matched_frames list\n",
    "        matched_frames.append(client_received_frames[first_c_id])\n",
    "        #print(curr_sf_id, first_c_id, len(matched_frames))\n",
    "\n",
    "with open(\"matched_client_received_frames.txt\", \"wb\") as fp:\n",
    "    pickle.dump(matched_frames, fp)\n",
    "#print(matched_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:56.095993Z",
     "start_time": "2019-11-18T13:02:56.068767Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# going through client_received_frames list and storing data into frames\n",
    "\n",
    "with open(\"matched_client_received_frames.txt\", \"rb\") as input_file:\n",
    "    mcrf = pickle.load(input_file)\n",
    "\n",
    "for i in range(len(client_received_frames)):\n",
    "    if i > len(mcrf)-1:\n",
    "        break\n",
    "    curr_cf = mcrf[i]\n",
    "    ccf_id = curr_cf[0]\n",
    "    ccf_time = curr_cf[1]\n",
    "    \n",
    "    csf_id = frames[i][0]\n",
    "\n",
    "    if ccf_id == csf_id:\n",
    "        frames[i][7] = ccf_time\n",
    "    else:\n",
    "        # this is an incredibly dumb way at parsing the data\n",
    "        new_id = frames[i+11][0]\n",
    "        if ccf_id == new_id:\n",
    "            frames[i+11][7] = ccf_time\n",
    "        else:\n",
    "            new_id = frames[i+12][0]\n",
    "            if ccf_id == new_id:\n",
    "                frames[i+12][7] = ccf_time\n",
    "            else:\n",
    "                print(ccf_id, csf_id, frames[i][0], frames[i+12][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:56.099949Z",
     "start_time": "2019-11-18T13:02:56.097033Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# search through network logs and extract the data from PCAP file which is now\n",
    "# a text file - export/conversion done with Wireshark\n",
    "\n",
    "network_log_folder = \"./network_logs/\"\n",
    "network_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(network_log_folder):\n",
    "    for file in f:\n",
    "        if '.pcap' in file:\n",
    "            network_folder_files.append(os.path.join(r, file))\n",
    "\n",
    "network_folder_file = network_folder_files[-1]\n",
    "split_nff = network_folder_file.split(\"/\")[-1].split(\".\")[0]\n",
    "new_txt = network_log_folder + split_nff + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:56.511977Z",
     "start_time": "2019-11-18T13:02:56.101291Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# reading through the network log and selecting out packets and associate data\n",
    "\n",
    "network_dict = {\n",
    "    \"19\" : 5, # 5G,\n",
    "    \"20\" : 4, # 4G/LTE\n",
    "    \"182\" : 0 # unknown\n",
    "}\n",
    "\n",
    "# reading the number of lines in the file\n",
    "with open(new_txt) as f:\n",
    "    num_lines_nl = sum(1 for _ in f)\n",
    "\n",
    "packets = []       \n",
    "network_log = open(new_txt, \"r\").readlines()\n",
    "for i in range(num_lines_nl):\n",
    "    curr_line = network_log[i]\n",
    "    #print(curr_line)\n",
    "    \n",
    "    if \"bytes on wire\" in curr_line:\n",
    "        cl_split = curr_line.split(\" \")\n",
    "        packet_id = cl_split[1].replace(\":\", \"\")\n",
    "        \n",
    "        # variable changes to 1 if a handover occurs \n",
    "        handover_event = 0 \n",
    "    if \"Epoch Time:\" in curr_line:\n",
    "        packet_time = re.findall(r'Epoch Time:(.+?)seconds', curr_line)[0]\n",
    "    if \"E-RABModificationIndication\" in curr_line:\n",
    "        handover_event = 1 \n",
    "    if \"transportLayerAddress(IPv4):\" in curr_line:\n",
    "        cl_split = curr_line.split(\" \")\n",
    "        network_ip = cl_split[-1].strip()\n",
    "        \n",
    "        nip_split = network_ip.split(\".\")[-1]\n",
    "        network_type = network_dict[nip_split]\n",
    "        \n",
    "        packet_data = [packet_id, packet_time, handover_event, network_type]\n",
    "        packets.append(packet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:56.517261Z",
     "start_time": "2019-11-18T13:02:56.513543Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# creating array of periods to show when network is 5G or 4G\n",
    "\n",
    "network_periods = []\n",
    "\n",
    "begin_time = 0 # assume time begun at 0 \n",
    "network_type = 5 # network began at 5G\n",
    "for i in range(len(packets)):\n",
    "    curr_packet = packets[i]\n",
    "    handover_time = curr_packet[1]\n",
    "    \n",
    "    period_data = [float(begin_time), float(handover_time), network_type]\n",
    "    network_periods.append(period_data)\n",
    "    begin_time = handover_time\n",
    "    if i != 0:\n",
    "        network_type = curr_packet[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:58.119545Z",
     "start_time": "2019-11-18T13:02:56.518233Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# match packets list to the frames numpy array\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    curr_frame = frames[i]\n",
    "    device_sent_time = curr_frame[6] / 1000\n",
    "    device_received_time = curr_frame[7] / 1000\n",
    "    \n",
    "    handover_during = []\n",
    "\n",
    "    for j in range(len(network_periods)):\n",
    "        curr_period = network_periods[j]\n",
    "        cp_begin = curr_period[0]\n",
    "        cp_end = curr_period[1]\n",
    "        cp_type = curr_period[2]\n",
    "        \n",
    "        if cp_begin < device_sent_time < cp_end: \n",
    "            frames[i][8] = cp_type\n",
    "            #print(\"network at sent: \", cp_type, \", \", device_sent_time, \", \", cp_begin, \" \", cp_end)\n",
    "            handover_during.append(cp_type)\n",
    "        if cp_begin < device_received_time < cp_end: \n",
    "            frames[i][9] = cp_type\n",
    "            #print(\"network at received: \", cp_type, \", \", device_received_time, \", \", cp_begin, \" \", cp_end)\n",
    "            handover_during.append(cp_type)\n",
    "\n",
    "    if np.sum(handover_during) == 9:\n",
    "        # if constant network leave value of 0\n",
    "        # if 5G>4G handover assign value of 1\n",
    "        # if 4G>5G handover assign value of 2\n",
    "        \n",
    "        if handover_during[0] == 5:\n",
    "            frames[i][10] = 1\n",
    "        else:\n",
    "            frames[i][10] = 2\n",
    "            \n",
    "        #print(cp_begin, cp_end, device_sent_time, device_received_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T13:02:58.130427Z",
     "start_time": "2019-11-18T13:02:58.120604Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed from 5G to 4G: 85  times, and 4G to 5G: 85  times\n",
      "Median time spent on 5G network before change is: 8.995527982711792 (ms), minimum is: 0.0460050106048584 (ms), and maximum is: 504.08662009239197 (ms)\n",
      "Median time spent on 4G network before change is: 1.092229962348938 (ms), minimum is: 0.0918588638305664 (ms), and maximum is: 679.1013910770416 (ms)\n"
     ]
    }
   ],
   "source": [
    "# analysing the handovers\n",
    "\n",
    "# changing from 5G to 4G, and 4G to 5G\n",
    "five_four = []\n",
    "four_five = []\n",
    "\n",
    "# duration spent on each network\n",
    "five = []\n",
    "four = []\n",
    "\n",
    "network_type = 5\n",
    "for i in range(len(network_periods)):\n",
    "    curr_period = network_periods[i]\n",
    "    new_network_type = curr_period[2]\n",
    "    \n",
    "    nnt_begin = curr_period[0]\n",
    "    nnt_end = curr_period[1]\n",
    "    \n",
    "    dur_on_type = nnt_end - nnt_begin\n",
    "    if new_network_type == 5:\n",
    "        five.append(dur_on_type)\n",
    "    if new_network_type == 4:\n",
    "        four.append(dur_on_type)\n",
    "    \n",
    "    if new_network_type == 0:\n",
    "        new_network_type = network_type\n",
    "\n",
    "    if network_type != new_network_type:\n",
    "        #print(\"changing from \", network_type, \" to \", new_network_type)\n",
    "        \n",
    "        if network_type == 5:\n",
    "            five_four.append(nnt_begin)\n",
    "        else:\n",
    "            four_five.append(nnt_begin)\n",
    "    \n",
    "    network_type = new_network_type\n",
    "    \n",
    "print(\"Changed from 5G to 4G:\", len(five_four), \" times, and 4G to 5G:\", \n",
    "      len(four_five), \" times\")\n",
    "\n",
    "five = five[1:-1]\n",
    "print(\"Median time spent on 5G network before change is:\", np.median(five), \"(ms), minimum is:\", \n",
    "      np.min(five), \"(ms), and maximum is:\", np.max(five), \"(ms)\")\n",
    "\n",
    "four = four[1:-1]\n",
    "print(\"Median time spent on 4G network before change is:\", np.median(four), \"(ms), minimum is:\", \n",
    "      np.min(four), \"(ms), and maximum is:\", np.max(four), \"(ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-18T14:08:14.730609Z",
     "start_time": "2019-11-18T14:08:14.688409Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 11842 frames were sent, experiment lasted for a total of 56.19185 minutes\n",
      "Changed from 5G to 4G: 85  times, and 4G to 5G: 85  times - totalling 170 handovers\n",
      "Phone detected 2803 location changes\n",
      "Overall median data transfer for whole experiment: 748.1795999999999 (ms)\n",
      "Average server processing times: 18.5334517522378 +- 10.15219806839911 (ms)\n",
      "Average client time gap: 793.3137859649123 +- 666.0245725576414 (ms)\n",
      "4985.0989\n",
      "Median data transfer time when continual 5G connection: 246.8162 (ms)\n",
      "Median data transfer time when continual 4G connection: 387.241 (ms)\n",
      "Median data transfer time when handover from 5G to 4G connection: 286.5229 (ms)\n",
      "Median data transfer time when handover from 4G to 5G connection: 878.9599499999999 (ms)\n",
      "Average frame size received from client on server 40257.83642965715\n",
      "Median time between frame sent from client 37.0 (ms)\n"
     ]
    }
   ],
   "source": [
    "# calculating the data transfer times for the whole experimental period\n",
    "\n",
    "print(\"In total,\", len(frames), \"frames were sent, experiment lasted for a total of\",\n",
    "     (frames[-2][7]-frames[0][6])/1000/60, \"minutes\")\n",
    "print(\"Changed from 5G to 4G:\", len(five_four), \" times, and 4G to 5G:\", len(four_five), \n",
    "      \" times - totalling\", len(five_four)+len(four_five), \"handovers\")\n",
    "print(\"Phone detected\", len(location_changes), \"location changes\")\n",
    "\n",
    "# did handover occur\n",
    "handover_question = frames[:,10]\n",
    "network_cs = frames[:,8] # network when client sent\n",
    "network_cr = frames[:,9] # network when client received\n",
    "\n",
    "# client processing time\n",
    "client_sent_time = frames[:,6]\n",
    "client_received_time = frames[:,7]\n",
    "client_tot_time = client_received_time - client_sent_time\n",
    "\n",
    "# server processing time\n",
    "server_process_tot = frames[:,5]\n",
    "\n",
    "data_transfer_time = client_tot_time - server_process_tot\n",
    "overall_med_dtt = np.median(data_transfer_time)\n",
    "print(\"Overall median data transfer for whole experiment:\", overall_med_dtt, \"(ms)\")\n",
    "\n",
    "###\n",
    "\n",
    "when_5g = []\n",
    "when_4g = []\n",
    "\n",
    "when_5g_4g = [] # 5G to 4G\n",
    "when_4g_5g = [] # 4G to 5G\n",
    "\n",
    "server_processing_times = []\n",
    "client_time_gap = []\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    curr_frame = frames[i]\n",
    "    curr_network_type_cs = curr_frame[8]\n",
    "    curr_network_type_cr = curr_frame[9]\n",
    "    \n",
    "    curr_cst = curr_frame[6]\n",
    "    curr_crt = curr_frame[7]\n",
    "    curr_tott = curr_crt - curr_cst\n",
    "    #print(curr_tott, curr_crt, curr_cst)\n",
    "        \n",
    "    curr_spt = curr_frame[5]\n",
    "    server_processing_times.append(curr_spt)\n",
    "    \n",
    "    # data transfer time\n",
    "    curr_dtt = curr_tott - curr_spt\n",
    "    #print(curr_dtt, curr_tott, curr_spt)\n",
    "    \n",
    "    curr_ncs = curr_frame[8]\n",
    "    curr_ncr = curr_frame[9]\n",
    "\n",
    "    if curr_network_type_cs == curr_network_type_cr:\n",
    "        # data transfer times when on the same network type continually from\n",
    "        # frame sent to receive\n",
    "        if curr_network_type_cs == 5:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                when_5g.append(curr_dtt)\n",
    "        if curr_network_type_cs == 4:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                when_4g.append(curr_dtt)\n",
    "    else:\n",
    "        # if handover occurs betwene sending and receiving a frame\n",
    "        if curr_ncs == 5:\n",
    "            # if from 5G to 4G handover\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                client_time_gap.append(curr_dtt)\n",
    "                when_5g_4g.append(curr_dtt)\n",
    "        if curr_ncs == 4:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                client_time_gap.append(curr_dtt)\n",
    "                when_4g_5g.append(curr_dtt)\n",
    "\n",
    "avg_spt = np.average(server_processing_times)\n",
    "std_spt = np.std(server_processing_times)\n",
    "print(\"Average server processing times:\", avg_spt, \"+-\", std_spt, \"(ms)\")\n",
    "\n",
    "avg_ctg = np.average(client_time_gap)\n",
    "std_ctg = np.std(client_time_gap)\n",
    "print(\"Average client time gap:\", avg_ctg, \"+-\", std_ctg, \"(ms)\")\n",
    "            \n",
    "med_5g = np.median(when_5g)\n",
    "print(np.max(when_5g))\n",
    "print(\"Median data transfer time when continual 5G connection:\", med_5g, \"(ms)\")\n",
    "\n",
    "med_4g = np.median(when_4g)\n",
    "print(\"Median data transfer time when continual 4G connection:\", med_4g, \"(ms)\")\n",
    "\n",
    "med_5g_4g = np.median(when_5g_4g)\n",
    "print(\"Median data transfer time when handover from 5G to 4G connection:\", med_5g_4g, \"(ms)\")\n",
    "\n",
    "med_4g_5g = np.median(when_4g_5g)\n",
    "print(\"Median data transfer time when handover from 4G to 5G connection:\", med_4g_5g, \"(ms)\")\n",
    "\n",
    "frames_size = frames[:,1]\n",
    "avg_fs = np.average(frames_size) # in bits\n",
    "afs_bytes = avg_fs/8\n",
    "print(\"Average frame size received from client on server\", avg_fs)\n",
    "\n",
    "client_sent_orig = frames[:,6]\n",
    "client_sent_shift = np.roll(client_sent_orig, -1)\n",
    "cs_time_diff = client_sent_shift - client_sent_orig\n",
    "cs_time_diff = cs_time_diff[cs_time_diff > 0]\n",
    "cstd_med = np.median(cs_time_diff)\n",
    "print(\"Median time between frame sent from client:\", cstd_med, \"(ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-15T07:55:02.425867Z",
     "start_time": "2019-11-15T07:55:01.406528Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plotting location data onto Google Maps\n",
    "\n",
    "# load 5GTN data\n",
    "kml_file = path.join(\"5GTN coverage.kml\")\n",
    "kml_parsed = etree.parse(kml_file)\n",
    "kml_to_string = etree.tostring(kml_parsed, pretty_print=True).decode(\"utf-8\") \n",
    "\n",
    "#print(kml_to_string)\n",
    "\n",
    "lat_list = [float(item[0]) for item in location_changes]\n",
    "long_list = [float(item[1]) for item in location_changes]\n",
    "\n",
    "uni_map = gmplot.GoogleMapPlotter(lat_list[0], long_list[0], 17) \n",
    "\n",
    "#uni_map.scatter(lat_list, long_list, '#FFFFFF', size=1, marker=False) \n",
    "uni_map.plot(lat_list, long_list, 'red', edge_width=2.5) \n",
    "\n",
    "# comparing the times when in certain network types, and the locations\n",
    "loc_5g = []\n",
    "loc_4g = []\n",
    "for i in range(len(network_periods)):\n",
    "    curr_period = network_periods[i]\n",
    "    cp_begin = curr_period[0]\n",
    "    cp_end = curr_period[1]\n",
    "    cp_type = curr_period[2]\n",
    "    for j in range(len(location_changes)):\n",
    "        curr_loc = location_changes[j]\n",
    "        cl_time = float(curr_loc[2]) / 1000\n",
    "        curr_lat = float(curr_loc[0])\n",
    "        curr_long = float(curr_loc[1])\n",
    "        if cp_begin < cl_time < cp_end:\n",
    "            if cp_type == 5:\n",
    "                loc_5g.append([curr_lat, curr_long])\n",
    "            if cp_type == 4:\n",
    "                loc_4g.append([curr_lat, curr_long])\n",
    "                \n",
    "# plotting 5G locations\n",
    "fiveg_lat_list = [float(item[0]) for item in loc_5g]\n",
    "fiveg_long_list = [float(item[1]) for item in loc_5g]\n",
    "uni_map.scatter(fiveg_lat_list, fiveg_long_list, 'orange', size=1, marker=False) \n",
    "\n",
    "# plotting 4G locations\n",
    "fourg_lat_list = [float(item[0]) for item in loc_4g]\n",
    "fourg_long_list = [float(item[1]) for item in loc_4g]\n",
    "uni_map.scatter(fourg_lat_list, fourg_long_list, 'blue', size=1, marker=False) \n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx], idx\n",
    "\n",
    "loc_changes_times = [float(item[2])/1000 for item in location_changes]\n",
    "\n",
    "# going through the times when on a new network type and plot\n",
    "fiveg_fourg = np.zeros([len(five_four), 2])\n",
    "for i in range(len(five_four)):\n",
    "    curr_five = five_four[i]\n",
    "    nearest_time = find_nearest(loc_changes_times, curr_five)\n",
    "    nt_index = nearest_time[1]\n",
    "    curr_lat = float(location_changes[nt_index][0])\n",
    "    curr_long = float(location_changes[nt_index][1])\n",
    "    \n",
    "    fiveg_fourg[i][0] = curr_lat\n",
    "    fiveg_fourg[i][1] = curr_long\n",
    "    \n",
    "for i in range(len(fiveg_fourg)):\n",
    "    curr_llat = fiveg_fourg[i][0]\n",
    "    curr_llong = fiveg_fourg[i][1]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'orangered') \n",
    "#uni_map.marker(fiveg_fourg[:,0], fiveg_fourg[:,1], 'purple', size=1, marker=False)\n",
    "\n",
    "fourg_fiveg = np.zeros([len(four_five), 2])\n",
    "for i in range(len(four_five)):\n",
    "    curr_four = four_five[i]\n",
    "    nearest_time = find_nearest(loc_changes_times, curr_four)\n",
    "    nt_index = nearest_time[1]\n",
    "    curr_lat = float(location_changes[nt_index][0])\n",
    "    curr_long = float(location_changes[nt_index][1])\n",
    "    \n",
    "    fourg_fiveg[i][0] = curr_lat\n",
    "    fourg_fiveg[i][1] = curr_long\n",
    "\n",
    "for i in range(len(fourg_fiveg)):\n",
    "    curr_llat = fourg_fiveg[i][0]\n",
    "    curr_llong = fourg_fiveg[i][1]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'steelblue') \n",
    "#uni_map.marker(fourg_fiveg[:,0], fourg_fiveg[:,1], 'green', size=1, marker=False)\n",
    "    \n",
    "# manually plotting 5G and LTE modems\n",
    "uni_map.marker(65.0578097,25.4687127, 'orange') # 5G\n",
    "\n",
    "# these coords are the wrong way round - long then lat\n",
    "lte_modems = [\n",
    "    [25.4687287,65.0576514],\n",
    "    [25.4692223,65.0581491],\n",
    "    [25.4694208,65.0581717],\n",
    "    [25.4657354,65.0586965],\n",
    "    [25.4662504,65.0588051],\n",
    "    [25.4688253,65.0590946],\n",
    "    [25.4692277,65.0578708],\n",
    "    [25.4693081,65.0581672]\n",
    "]\n",
    "\n",
    "lte_lats = [float(item[1]) for item in lte_modems]\n",
    "lte_longs = [float(item[0]) for item in lte_modems]\n",
    "for i in range(len(lte_lats)):\n",
    "    curr_llat = lte_lats[i]\n",
    "    curr_llong = lte_longs[i]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'blue') # 4G/LTE\n",
    "\n",
    "uni_map.draw(\"location_changes.html\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
