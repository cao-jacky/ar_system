{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:23:57.824945Z",
     "start_time": "2019-12-09T15:23:57.707840Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import mmap\n",
    "\n",
    "import pickle\n",
    "import multiprocessing \n",
    "\n",
    "import csv\n",
    "\n",
    "import gmplot\n",
    "from os import path\n",
    "from lxml import etree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:06:53.158617Z",
     "start_time": "2019-12-09T15:06:53.150570Z"
    }
   },
   "outputs": [],
   "source": [
    "curr_day = \"091219\"\n",
    "\n",
    "# Searching through server logs - no particular need to do so\n",
    "server_log_folder = \"./server_logs/\" + curr_day\n",
    "server_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(server_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            server_folder_files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:10:04.079044Z",
     "start_time": "2019-12-09T15:10:03.954957Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse through the test_receive.txt file from server\n",
    "\n",
    "rec_frames = []\n",
    "\n",
    "test_receive = \"server_logs/\" + curr_day + \"/test_receive.txt\"\n",
    "with open(test_receive) as search:\n",
    "    for line in search:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if \"receive frameID :\" in line:\n",
    "            frame_no = int(re.findall(r'receive frameID :(.+?), at time :', line)[0])\n",
    "            rec_frames.append(frame_no)\n",
    "                    \n",
    "frames = np.zeros([len(rec_frames), 15])\n",
    "\"\"\" \n",
    "The columns represent:\n",
    "[0] : frame ID\n",
    "[1] : frame size received\n",
    "[2] : transmission delay\n",
    "[3] : size of the result sent\n",
    "[4] : time result was sent from server \n",
    "[5] : time taken to process the frame\n",
    "[6] : time the frame was sent from device  \n",
    "[7] : time a result was received on the device  \n",
    "[8] : whether connection was 5G or 4G when frame sent from device\n",
    "[9] : whether connection was 5G or 4G when result recieved on device\n",
    "[10] : whether a handover occured between frame sent and result received on device\n",
    "[11] : closest location: latitude\n",
    "[12] : closest location: longitude\n",
    "[13] : time server received the result\n",
    "[14] : time client sent from device according to server log\n",
    "\"\"\"\n",
    "\n",
    "# reading the number of lines in the file\n",
    "with open(test_receive) as f:\n",
    "    num_lines_tr = sum(1 for _ in f)\n",
    "    \n",
    "contents_tr = open(test_receive, \"r\").readlines()\n",
    "no_frame_parsed = 0 \n",
    "for i in range(num_lines_tr):\n",
    "    curr_line = contents_tr[i]\n",
    "    \n",
    "    if \"receive frameID :\" in curr_line:\n",
    "        frame_no = int(re.findall(r'receive frameID :(.+?), at time :', curr_line)[0])\n",
    "        frames[no_frame_parsed][0] = frame_no\n",
    "        \n",
    "        frame_size_rec = float(re.findall(r', has size:(.+?), transmission delay:', curr_line)[0])\n",
    "        frames[no_frame_parsed][1] = frame_size_rec\n",
    "        \n",
    "        server_received_time = float(re.findall(r', at time : (.+?), sent out ', curr_line)[0])\n",
    "        frames[no_frame_parsed][13] = server_received_time\n",
    "    \n",
    "        client_send_time = float(re.findall(r'from vehicle at time: (.+?), has size:', curr_line)[0])\n",
    "        frames[no_frame_parsed][14] = client_send_time\n",
    "    \n",
    "        no_frame_parsed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:10:42.115219Z",
     "start_time": "2019-12-09T15:10:42.007033Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# parse through the test_process.txt file from server\n",
    "\n",
    "process_frames = []\n",
    "\n",
    "test_process = \"server_logs/\" + curr_day + \"/test_process.txt\"\n",
    "with open(test_process) as search:\n",
    "    for line in search:\n",
    "        line = line.rstrip()  # remove '\\n' at end of line\n",
    "        if \"time_process_pic of frameid of:\" in line:\n",
    "            frame_no = int(re.findall(r'time_process_pic of frameid of:(.+?)takes: ', line)[0])\n",
    "            process_frames.append(frame_no)\n",
    "            \n",
    "# reading the number of lines in the file\n",
    "with open(test_process) as f:\n",
    "    num_lines_tp = sum(1 for _ in f)\n",
    "    \n",
    "contents_tp = open(test_process, \"r\").readlines()\n",
    "no_frame_parsed = 0 \n",
    "for i in range(num_lines_tp):\n",
    "    curr_line = contents_tp[i]\n",
    "    \n",
    "    if \"time_process_pic of frameid of:\" in curr_line:\n",
    "        frame_no = int(re.findall(r'time_process_pic of frameid of:(.+?)takes: ', curr_line)[0])\n",
    "        if frame_no == frames[no_frame_parsed][0]:\n",
    "            frame_process_time = re.findall(r'takes:(.+?)milliseconds', curr_line)[0]\n",
    "            frame_process_time = float(re.findall(r\"'(.+?)'\", frame_process_time)[0])\n",
    "            frames[no_frame_parsed][5] = frame_process_time\n",
    "            \n",
    "        no_frame_parsed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:18:06.099419Z",
     "start_time": "2019-12-09T15:18:06.093671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.5334517522378 10.15219806839911\n"
     ]
    }
   ],
   "source": [
    "server_processing = frames[:,5]\n",
    "avg_sp = np.nanmean(server_processing)\n",
    "std_sp = np.std(server_processing)\n",
    "print(avg_sp, std_sp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:29:24.484508Z",
     "start_time": "2019-12-09T15:29:24.472078Z"
    }
   },
   "outputs": [],
   "source": [
    "curr_day = \"071119\"\n",
    "\n",
    "# Searching through server logs - no particular need to do so\n",
    "server_log_folder = \"./server_logs/\" + curr_day\n",
    "server_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(server_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            server_folder_files.append(os.path.join(r, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:00.546092Z",
     "start_time": "2019-12-09T15:32:00.521831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1574318974.786', './device_logs/old/arhud_logs/logcat_1574318974786.txt'], ['1574319134.355', './device_logs/old/arhud_logs/logcat_1574319134355.txt'], ['1574319190.11', './device_logs/old/arhud_logs/logcat_1574319190110.txt'], ['1574319218.283', './device_logs/old/arhud_logs/logcat_1574319218283.txt'], ['1574321085.538', './device_logs/old/arhud_logs/logcat_1574321085538.txt'], ['1574321171.173', './device_logs/old/arhud_logs/logcat_1574321171173.txt']]\n"
     ]
    }
   ],
   "source": [
    "# Searching through device logs \n",
    "\n",
    "client_log_folder = \"./device_logs/old/arhud_logs/\"\n",
    "client_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(client_log_folder):\n",
    "    for file in f:\n",
    "        if '.txt' in file:\n",
    "            client_folder_files.append(os.path.join(r, file))\n",
    "            \n",
    "device_log_files = []\n",
    "for curr_file in client_folder_files:\n",
    "    cf_orig = curr_file\n",
    "    curr_file = curr_file.split(\"/\")[-1].split(\"_\")\n",
    "    cf_time = float(curr_file[1].split(\".txt\")[0]) / 1000\n",
    "    \n",
    "    file_info = [str(cf_time), cf_orig]\n",
    "    globals()[\"device_log_files\"].append(file_info)\n",
    "\n",
    "# sort by unix_timestamp and manually select files from 071119\n",
    "device_log_files = sorted(device_log_files, key=operator.itemgetter(0))[-6:]\n",
    "\n",
    "print(device_log_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:34:29.819468Z",
     "start_time": "2019-12-09T15:34:29.805865Z"
    }
   },
   "outputs": [],
   "source": [
    "client_sent_frames = []\n",
    "client_received_frames = []\n",
    "\n",
    "location_changes = []\n",
    "\n",
    "for i in range(len(device_log_files)):\n",
    "    curr_log_item = device_log_files[i]\n",
    "    curr_log_file = curr_log_item[1]\n",
    "    \n",
    "    # reading the number of lines in the file\n",
    "    with open(curr_log_file) as f:\n",
    "        num_lines_cf = sum(1 for _ in f)\n",
    "\n",
    "    contents_cl = open(curr_log_file, \"r\").readlines()\n",
    "    for i in range(num_lines_cf):\n",
    "        curr_line = contents_cl[i]\n",
    "\n",
    "        if \"sent at\" in curr_line:\n",
    "            frame_no = int(re.findall(r'Frame(.+?)sent at', curr_line)[0])\n",
    "            frame_time_sent = curr_line.split(\" \")[-1].replace('\\n', '')   \n",
    "        \n",
    "            frame_data = [frame_no, frame_time_sent, \"sent\"]            \n",
    "            client_sent_frames.append(frame_data)\n",
    "            \n",
    "        if \"received at\" in curr_line:\n",
    "            frame_no = int(re.findall(r'res for frame(.+?)received at', curr_line)[0])\n",
    "            res_time_rec = curr_line.split(\" \")[-1].replace('\\n', '')   \n",
    "        \n",
    "            frame_data = [frame_no, res_time_rec, \"received\"]     \n",
    "            client_received_frames.append(frame_data)\n",
    "            \n",
    "        if \"location is\" in curr_line:\n",
    "            split_curr_line = curr_line.split(\" \")\n",
    "            lat = split_curr_line[12]\n",
    "            long = split_curr_line[15]\n",
    "            loc_time = split_curr_line[9]\n",
    "            \n",
    "            location_changes.append([lat, long, loc_time, frame_no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:04.909149Z",
     "start_time": "2019-12-09T15:32:04.898583Z"
    }
   },
   "outputs": [],
   "source": [
    "# search through network logs and extract the data from PCAP file which is now\n",
    "# a text file - export/conversion done with Wireshark\n",
    "\n",
    "network_log_folder = \"./network_logs/\"\n",
    "network_folder_files = []\n",
    "\n",
    "for r, d, f in os.walk(network_log_folder):\n",
    "    for file in f:\n",
    "        if '.pcap' in file:\n",
    "            network_folder_files.append(os.path.join(r, file))\n",
    "\n",
    "network_folder_file = network_folder_files[-1]\n",
    "split_nff = network_folder_file.split(\"/\")[-1].split(\".\")[0]\n",
    "new_txt = network_log_folder + split_nff + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:05.786116Z",
     "start_time": "2019-12-09T15:32:05.383360Z"
    }
   },
   "outputs": [],
   "source": [
    "# reading through the network log and selecting out packets and associate data\n",
    "\n",
    "network_dict = {\n",
    "    \"19\" : 5, # 5G,\n",
    "    \"20\" : 4, # 4G/LTE\n",
    "    \"182\" : 0 # unknown\n",
    "}\n",
    "\n",
    "# reading the number of lines in the file\n",
    "with open(new_txt) as f:\n",
    "    num_lines_nl = sum(1 for _ in f)\n",
    "\n",
    "packets = []       \n",
    "network_log = open(new_txt, \"r\").readlines()\n",
    "for i in range(num_lines_nl):\n",
    "    curr_line = network_log[i]\n",
    "    #print(curr_line)\n",
    "    \n",
    "    if \"bytes on wire\" in curr_line:\n",
    "        cl_split = curr_line.split(\" \")\n",
    "        packet_id = cl_split[1].replace(\":\", \"\")\n",
    "        \n",
    "        # variable changes to 1 if a handover occurs \n",
    "        handover_event = 0 \n",
    "    if \"Epoch Time:\" in curr_line:\n",
    "        packet_time = re.findall(r'Epoch Time:(.+?)seconds', curr_line)[0]\n",
    "    if \"E-RABModificationIndication\" in curr_line:\n",
    "        handover_event = 1 \n",
    "    if \"transportLayerAddress(IPv4):\" in curr_line:\n",
    "        cl_split = curr_line.split(\" \")\n",
    "        network_ip = cl_split[-1].strip()\n",
    "        \n",
    "        nip_split = network_ip.split(\".\")[-1]\n",
    "        network_type = network_dict[nip_split]\n",
    "        \n",
    "        packet_data = [packet_id, packet_time, handover_event, network_type]\n",
    "        packets.append(packet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:05.872777Z",
     "start_time": "2019-12-09T15:32:05.869683Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating array of periods to show when network is 5G or 4G\n",
    "\n",
    "network_periods = []\n",
    "\n",
    "begin_time = 0 # assume time begun at 0 \n",
    "network_type = 5 # network began at 5G\n",
    "for i in range(len(packets)):\n",
    "    curr_packet = packets[i]\n",
    "    handover_time = curr_packet[1]\n",
    "    \n",
    "    period_data = [float(begin_time), float(handover_time), network_type]\n",
    "    network_periods.append(period_data)\n",
    "    begin_time = handover_time\n",
    "    if i != 0:\n",
    "        network_type = curr_packet[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:07.482522Z",
     "start_time": "2019-12-09T15:32:06.260199Z"
    }
   },
   "outputs": [],
   "source": [
    "# match packets list to the frames numpy array\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    curr_frame = frames[i]\n",
    "    device_sent_time = curr_frame[6] / 1000\n",
    "    device_received_time = curr_frame[7] / 1000\n",
    "    \n",
    "    handover_during = []\n",
    "\n",
    "    for j in range(len(network_periods)):\n",
    "        curr_period = network_periods[j]\n",
    "        cp_begin = curr_period[0]\n",
    "        cp_end = curr_period[1]\n",
    "        cp_type = curr_period[2]\n",
    "        \n",
    "        if cp_begin < device_sent_time < cp_end: \n",
    "            frames[i][8] = cp_type\n",
    "            #print(\"network at sent: \", cp_type, \", \", device_sent_time, \", \", cp_begin, \" \", cp_end)\n",
    "            handover_during.append(cp_type)\n",
    "        if cp_begin < device_received_time < cp_end: \n",
    "            frames[i][9] = cp_type\n",
    "            #print(\"network at received: \", cp_type, \", \", device_received_time, \", \", cp_begin, \" \", cp_end)\n",
    "            handover_during.append(cp_type)\n",
    "\n",
    "    if np.sum(handover_during) == 9:\n",
    "        # if constant network leave value of 0\n",
    "        # if 5G>4G handover assign value of 1\n",
    "        # if 4G>5G handover assign value of 2\n",
    "        \n",
    "        if handover_during[0] == 5:\n",
    "            frames[i][10] = 1\n",
    "        else:\n",
    "            frames[i][10] = 2\n",
    "            \n",
    "        #print(cp_begin, cp_end, device_sent_time, device_received_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:07.491340Z",
     "start_time": "2019-12-09T15:32:07.483937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed from 5G to 4G: 85  times, and 4G to 5G: 85  times\n",
      "Median time spent on 5G network before change is: 8.995527982711792 (ms), minimum is: 0.0460050106048584 (ms), and maximum is: 504.08662009239197 (ms)\n",
      "Median time spent on 4G network before change is: 1.092229962348938 (ms), minimum is: 0.0918588638305664 (ms), and maximum is: 679.1013910770416 (ms)\n"
     ]
    }
   ],
   "source": [
    "# analysing the handovers\n",
    "\n",
    "# changing from 5G to 4G, and 4G to 5G\n",
    "five_four = []\n",
    "four_five = []\n",
    "\n",
    "# duration spent on each network\n",
    "five = []\n",
    "four = []\n",
    "\n",
    "network_type = 5\n",
    "for i in range(len(network_periods)):\n",
    "    curr_period = network_periods[i]\n",
    "    new_network_type = curr_period[2]\n",
    "    \n",
    "    nnt_begin = curr_period[0]\n",
    "    nnt_end = curr_period[1]\n",
    "    \n",
    "    dur_on_type = nnt_end - nnt_begin\n",
    "    if new_network_type == 5:\n",
    "        five.append(dur_on_type)\n",
    "    if new_network_type == 4:\n",
    "        four.append(dur_on_type)\n",
    "    \n",
    "    if new_network_type == 0:\n",
    "        new_network_type = network_type\n",
    "\n",
    "    if network_type != new_network_type:\n",
    "        #print(\"changing from \", network_type, \" to \", new_network_type)\n",
    "        \n",
    "        if network_type == 5:\n",
    "            five_four.append(nnt_begin)\n",
    "        else:\n",
    "            four_five.append(nnt_begin)\n",
    "    \n",
    "    network_type = new_network_type\n",
    "    \n",
    "print(\"Changed from 5G to 4G:\", len(five_four), \" times, and 4G to 5G:\", \n",
    "      len(four_five), \" times\")\n",
    "\n",
    "five = five[1:-1]\n",
    "print(\"Median time spent on 5G network before change is:\", np.median(five), \"(ms), minimum is:\", \n",
    "      np.min(five), \"(ms), and maximum is:\", np.max(five), \"(ms)\")\n",
    "\n",
    "four = four[1:-1]\n",
    "print(\"Median time spent on 4G network before change is:\", np.median(four), \"(ms), minimum is:\", \n",
    "      np.min(four), \"(ms), and maximum is:\", np.max(four), \"(ms)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:07.552441Z",
     "start_time": "2019-12-09T15:32:07.492477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, 11842 frames were sent, experiment lasted for a total of 0.0 minutes\n",
      "Changed from 5G to 4G: 85  times, and 4G to 5G: 85  times - totalling 170 handovers\n",
      "Overall median data transfer for whole experiment: -14.27745 (ms)\n",
      "Average server processing times: 18.5334517522378 +- 10.15219806839911 (ms)\n",
      "Average client time gap: nan +- nan (ms)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-2f79312d02b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0mmed_5g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhen_5g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhen_5g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Median data transfer time when continual 5G connection:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmed_5g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(ms)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2619\u001b[0m     \"\"\"\n\u001b[1;32m   2620\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2621\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# calculating the data transfer times for the whole experimental period\n",
    "\n",
    "print(\"In total,\", len(frames), \"frames were sent, experiment lasted for a total of\",\n",
    "     (frames[-2][7]-frames[0][6])/1000/60, \"minutes\")\n",
    "print(\"Changed from 5G to 4G:\", len(five_four), \" times, and 4G to 5G:\", len(four_five), \n",
    "      \" times - totalling\", len(five_four)+len(four_five), \"handovers\")\n",
    "# print(\"Phone detected\", len(location_changes), \"location changes\")\n",
    "\n",
    "# did handover occur\n",
    "handover_question = frames[:,10]\n",
    "network_cs = frames[:,8] # network when client sent\n",
    "network_cr = frames[:,9] # network when client received\n",
    "\n",
    "# client processing time\n",
    "client_sent_time = frames[:,6]\n",
    "client_received_time = frames[:,7]\n",
    "client_tot_time = client_received_time - client_sent_time\n",
    "\n",
    "# server processing time\n",
    "server_process_tot = frames[:,5]\n",
    "\n",
    "data_transfer_time = client_tot_time - server_process_tot\n",
    "overall_med_dtt = np.median(data_transfer_time)\n",
    "print(\"Overall median data transfer for whole experiment:\", overall_med_dtt, \"(ms)\")\n",
    "\n",
    "###\n",
    "\n",
    "when_5g = []\n",
    "when_4g = []\n",
    "\n",
    "when_5g_4g = [] # 5G to 4G\n",
    "when_4g_5g = [] # 4G to 5G\n",
    "\n",
    "server_processing_times = []\n",
    "client_time_gap = []\n",
    "\n",
    "for i in range(len(frames)):\n",
    "    curr_frame = frames[i]\n",
    "    curr_network_type_cs = curr_frame[8]\n",
    "    curr_network_type_cr = curr_frame[9]\n",
    "    \n",
    "    curr_cst = curr_frame[6]\n",
    "    curr_crt = curr_frame[7]\n",
    "    curr_tott = curr_crt - curr_cst\n",
    "    #print(curr_tott, curr_crt, curr_cst)\n",
    "        \n",
    "    curr_spt = curr_frame[5]\n",
    "    server_processing_times.append(curr_spt)\n",
    "    \n",
    "    # data transfer time\n",
    "    curr_dtt = curr_tott - curr_spt\n",
    "    #print(curr_dtt, curr_tott, curr_spt)\n",
    "    \n",
    "    curr_ncs = curr_frame[8]\n",
    "    curr_ncr = curr_frame[9]\n",
    "\n",
    "    if curr_network_type_cs == curr_network_type_cr:\n",
    "        # data transfer times when on the same network type continually from\n",
    "        # frame sent to receive\n",
    "        if curr_network_type_cs == 5:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                when_5g.append(curr_dtt)\n",
    "        if curr_network_type_cs == 4:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                when_4g.append(curr_dtt)\n",
    "    else:\n",
    "        # if handover occurs betwene sending and receiving a frame\n",
    "        if curr_ncs == 5:\n",
    "            # if from 5G to 4G handover\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                client_time_gap.append(curr_dtt)\n",
    "                when_5g_4g.append(curr_dtt)\n",
    "        if curr_ncs == 4:\n",
    "            if 0 < curr_dtt < 5000:\n",
    "                client_time_gap.append(curr_dtt)\n",
    "                when_4g_5g.append(curr_dtt)\n",
    "\n",
    "avg_spt = np.average(server_processing_times)\n",
    "std_spt = np.std(server_processing_times)\n",
    "print(\"Average server processing times:\", avg_spt, \"+-\", std_spt, \"(ms)\")\n",
    "\n",
    "avg_ctg = np.average(client_time_gap)\n",
    "std_ctg = np.std(client_time_gap)\n",
    "print(\"Average client time gap:\", avg_ctg, \"+-\", std_ctg, \"(ms)\")\n",
    "            \n",
    "med_5g = np.median(when_5g)\n",
    "print(np.max(when_5g))\n",
    "print(\"Median data transfer time when continual 5G connection:\", med_5g, \"(ms)\")\n",
    "\n",
    "med_4g = np.median(when_4g)\n",
    "print(\"Median data transfer time when continual 4G connection:\", med_4g, \"(ms)\")\n",
    "\n",
    "med_5g_4g = np.median(when_5g_4g)\n",
    "print(\"Median data transfer time when handover from 5G to 4G connection:\", med_5g_4g, \"(ms)\")\n",
    "\n",
    "med_4g_5g = np.median(when_4g_5g)\n",
    "print(\"Median data transfer time when handover from 4G to 5G connection:\", med_4g_5g, \"(ms)\")\n",
    "\n",
    "frames_size = frames[:,1]\n",
    "avg_fs = np.average(frames_size) # in bits\n",
    "afs_bytes = avg_fs/8\n",
    "print(\"Average frame size received from client on server\", avg_fs)\n",
    "\n",
    "client_sent_orig = frames[:,6]\n",
    "client_sent_shift = np.roll(client_sent_orig, -1)\n",
    "cs_time_diff = client_sent_shift - client_sent_orig\n",
    "cs_time_diff = cs_time_diff[cs_time_diff > 0]\n",
    "cstd_med = np.median(cs_time_diff)\n",
    "print(\"Median time between frame sent from client:\", cstd_med, \"(ms)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T15:32:07.677337Z",
     "start_time": "2019-12-09T15:32:07.659015Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'location'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-a1c07b9ed0b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(kml_to_string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation_changes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlong_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation_changes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-a1c07b9ed0b5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#print(kml_to_string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlat_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation_changes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlong_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocation_changes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'location'"
     ]
    }
   ],
   "source": [
    "# plotting location data onto Google Maps\n",
    "\n",
    "# load 5GTN data\n",
    "kml_file = path.join(\"5GTN coverage.kml\")\n",
    "kml_parsed = etree.parse(kml_file)\n",
    "kml_to_string = etree.tostring(kml_parsed, pretty_print=True).decode(\"utf-8\") \n",
    "\n",
    "#print(kml_to_string)\n",
    "\n",
    "lat_list = [float(item[0]) for item in location_changes]\n",
    "long_list = [float(item[1]) for item in location_changes]\n",
    "\n",
    "uni_map = gmplot.GoogleMapPlotter(lat_list[0], long_list[0], 17) \n",
    "\n",
    "#uni_map.scatter(lat_list, long_list, '#FFFFFF', size=1, marker=False) \n",
    "uni_map.plot(lat_list, long_list, 'red', edge_width=2.5) \n",
    "\n",
    "# comparing the times when in certain network types, and the locations\n",
    "loc_5g = []\n",
    "loc_4g = []\n",
    "for i in range(len(network_periods)):\n",
    "    curr_period = network_periods[i]\n",
    "    cp_begin = curr_period[0]\n",
    "    cp_end = curr_period[1]\n",
    "    cp_type = curr_period[2]\n",
    "    for j in range(len(location_changes)):\n",
    "        curr_loc = location_changes[j]\n",
    "        cl_time = float(curr_loc[2]) / 1000\n",
    "        curr_lat = float(curr_loc[0])\n",
    "        curr_long = float(curr_loc[1])\n",
    "        if cp_begin < cl_time < cp_end:\n",
    "            if cp_type == 5:\n",
    "                loc_5g.append([curr_lat, curr_long])\n",
    "            if cp_type == 4:\n",
    "                loc_4g.append([curr_lat, curr_long])\n",
    "                \n",
    "# plotting 5G locations\n",
    "fiveg_lat_list = [float(item[0]) for item in loc_5g]\n",
    "fiveg_long_list = [float(item[1]) for item in loc_5g]\n",
    "uni_map.scatter(fiveg_lat_list, fiveg_long_list, 'orange', size=1, marker=False) \n",
    "\n",
    "# plotting 4G locations\n",
    "fourg_lat_list = [float(item[0]) for item in loc_4g]\n",
    "fourg_long_list = [float(item[1]) for item in loc_4g]\n",
    "uni_map.scatter(fourg_lat_list, fourg_long_list, 'blue', size=1, marker=False) \n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return array[idx], idx\n",
    "\n",
    "loc_changes_times = [float(item[2])/1000 for item in location_changes]\n",
    "\n",
    "# going through the times when on a new network type and plot\n",
    "fiveg_fourg = np.zeros([len(five_four), 2])\n",
    "for i in range(len(five_four)):\n",
    "    curr_five = five_four[i]\n",
    "    nearest_time = find_nearest(loc_changes_times, curr_five)\n",
    "    nt_index = nearest_time[1]\n",
    "    curr_lat = float(location_changes[nt_index][0])\n",
    "    curr_long = float(location_changes[nt_index][1])\n",
    "    \n",
    "    fiveg_fourg[i][0] = curr_lat\n",
    "    fiveg_fourg[i][1] = curr_long\n",
    "    \n",
    "for i in range(len(fiveg_fourg)):\n",
    "    curr_llat = fiveg_fourg[i][0]\n",
    "    curr_llong = fiveg_fourg[i][1]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'orangered') \n",
    "#uni_map.marker(fiveg_fourg[:,0], fiveg_fourg[:,1], 'purple', size=1, marker=False)\n",
    "\n",
    "fourg_fiveg = np.zeros([len(four_five), 2])\n",
    "for i in range(len(four_five)):\n",
    "    curr_four = four_five[i]\n",
    "    nearest_time = find_nearest(loc_changes_times, curr_four)\n",
    "    nt_index = nearest_time[1]\n",
    "    curr_lat = float(location_changes[nt_index][0])\n",
    "    curr_long = float(location_changes[nt_index][1])\n",
    "    \n",
    "    fourg_fiveg[i][0] = curr_lat\n",
    "    fourg_fiveg[i][1] = curr_long\n",
    "\n",
    "for i in range(len(fourg_fiveg)):\n",
    "    curr_llat = fourg_fiveg[i][0]\n",
    "    curr_llong = fourg_fiveg[i][1]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'steelblue') \n",
    "#uni_map.marker(fourg_fiveg[:,0], fourg_fiveg[:,1], 'green', size=1, marker=False)\n",
    "    \n",
    "# manually plotting 5G and LTE modems\n",
    "uni_map.marker(65.0578097,25.4687127, 'orange') # 5G\n",
    "\n",
    "# these coords are the wrong way round - long then lat\n",
    "lte_modems = [\n",
    "    [25.4687287,65.0576514],\n",
    "    [25.4692223,65.0581491],\n",
    "    [25.4694208,65.0581717],\n",
    "    [25.4657354,65.0586965],\n",
    "    [25.4662504,65.0588051],\n",
    "    [25.4688253,65.0590946],\n",
    "    [25.4692277,65.0578708],\n",
    "    [25.4693081,65.0581672]\n",
    "]\n",
    "\n",
    "lte_lats = [float(item[1]) for item in lte_modems]\n",
    "lte_longs = [float(item[0]) for item in lte_modems]\n",
    "for i in range(len(lte_lats)):\n",
    "    curr_llat = lte_lats[i]\n",
    "    curr_llong = lte_longs[i]\n",
    "    uni_map.marker(curr_llat, curr_llong, 'blue') # 4G/LTE\n",
    "\n",
    "uni_map.draw(\"location_changes_new.html\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
